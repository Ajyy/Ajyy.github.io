<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Neural Machine Translation of Rare Words with Subword Units</title>
      <link href="/2019/09/15/Neural-Machine-Translation-of-Rare-Words-with-Subword-Units/"/>
      <url>/2019/09/15/Neural-Machine-Translation-of-Rare-Words-with-Subword-Units/</url>
      
        <content type="html"><![CDATA[<p>Rico Sennrich and Barry Haddow and Alexandra Birch<br>School of Informatics, University of Edinburgh<br><a href="https://arxiv.org/pdf/1508.07909.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1508.07909.pdf</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>文章主要是为了解决rare/out-of-vocabulary word的问题，在charator-based和word-based之间取了一个平衡。通过对训练数据进行分析，得出subword unit。因为在ESPNet看到了用subword unit去处理数据，BPE也已经应用在了语音领域，之前交流已经学习过了这个方法，因此再读一遍作为复习。</p><a id="more"></a><hr><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>解决rare words的翻译问题。 <br></p><p>目前的word-level的方法效果并不算好。论文提到了back-off的方法，即对于rare words，首先翻译成 UNK，然后在look up dictionary去得到结果。但是翻译并不总是一对一的。 <br></p><p>还有直接把rare words复制到target sentence里，这样的方法或许对姓名之类的单词效果比较好。但存在的问题是翻译常常要求音译或者morphologic change(形态上的变化)，尤其是当单词表不同的时候。</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><p><strong>Byte pair encoding(BPE</strong>)<img src="/images_2019.9.15/BPE.png" alt></p><p><em>vocab</em>是一个字典，键值表示每个单词出现的频率，这些单词已经被切割成一个个字符(也可以看成是subword unit)。<em>num_merges</em>即生成subword unit的数量，每次循环都生成一个subword unit。在每一个循环中，首先得到<em>pairs</em>，<em>get_stats</em>会得到所有相邻subword unit的，即任意(subword unit1, subword unit 2)的频率，然后存在<em>Pairs</em>里。在得到频率最高的pair即<em>best</em>后，用<em>merge_vocab</em>在<em>vocab</em>里把它们合并起来。</p><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>作者利用BPE和之前提到的word-level的方法，在数据集上测试效果，并且测量了unigram F1和BLEU（略）。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>BPE在训练数据更少的情况下取得了更好的效果。</p><h2 id="Future-Research"><a href="#Future-Research" class="headerlink" title="Future Research"></a>Future Research</h2><p>研究对于一个翻译任务的最优Vocabulary size。<br></p><p>研究针对双语来说，不仅利用一边的数据去得到Subword Unit，也利用另一边的数据去align。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Translation </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
