<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Semi-Supervised End-to-End Speech Recognition</title>
      <link href="/2019/09/16/Semi-Supervised-End-to-End-Speech-Recognition/"/>
      <url>/2019/09/16/Semi-Supervised-End-to-End-Speech-Recognition/</url>
      
        <content type="html"><![CDATA[<p>NTT Communication Science Laboratories and Center for Language and Speech Processing, Johns Hopkins University</p><p><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1746.pdf" target="_blank" rel="noopener">https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1746.pdf</a></p><a id="more"></a><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本文主要提出一种半监督的方式，即在原来的基础上，加入一个Autoencoder，并且改进loss function，利用GAN或KLD来减少speech和text feature的分布差距。</p><hr><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>准备speech-to-text corpora需要耗费大量的人力，因此可以利用半监督学习来减少准备数据的精力。本文提到直接上无监督学习对于语音领域难度过大，因此relax到半监督学习。</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><p>本文提出了一种半监督学习的Framework，如下图：</p><p><img src="/images_2019.9.16/Semi_supervised_architecture.png" alt="Semi_supervised_architecture"></p><p>其中input分为两部分：一部分是speech，一部分是text，而speech到text可以理解为监督学习的方式，text到text即是autoencoder，因为speech的input length往往大于text的，所以speech input要过一个pyramid BLSTM，来减少length。</p><p>具体算法参见下图：</p><p><img src="/images_2019.9.16/semi_supervised_training_algo.png" alt="Semi_supervised_architecture"></p><p>可以看到loss具体分成三部分，其中两部分是speech-to-text和text-to-text的loss，第三个loss是inter-domain feature(即经过encoder的feature) 的speech和text数据的分布差距。具体来说，有两种方式来测量分布差距，一个是利用KLD divergence，另一种是利用GAN，即创建一个新的Network，作为discriminator，进行打分。（与我实习时，和调研GAIL用的方法类似）</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>如下图，可以看到效果有一定提升。</p><p><img src="/images_2019.9.16/semi_supervised_evaluation.png" alt="semi_supervised_evaluation"></p><h2 id="Feature-Research"><a href="#Feature-Research" class="headerlink" title="Feature Research"></a>Feature Research</h2><p>作者提出未来想调查是否当数据量增大时，效果依然会提升。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Automatic Speech Recognition </tag>
            
            <tag> Semi-Supervised Learning </tag>
            
            <tag> Model Architecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural Machine Translation of Rare Words with Subword Units</title>
      <link href="/2019/09/15/Neural-Machine-Translation-of-Rare-Words-with-Subword-Units/"/>
      <url>/2019/09/15/Neural-Machine-Translation-of-Rare-Words-with-Subword-Units/</url>
      
        <content type="html"><![CDATA[<p>Rico Sennrich and Barry Haddow and Alexandra Birch<br>School of Informatics, University of Edinburgh<br><a href="https://arxiv.org/pdf/1508.07909.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1508.07909.pdf</a></p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>文章主要是为了解决rare/out-of-vocabulary word的问题，在charator-based和word-based之间取了一个平衡。通过对训练数据进行分析，得出subword unit。因为在ESPNet看到了用subword unit去处理数据，BPE也已经应用在了语音领域，之前交流已经学习过了这个方法，因此再读一遍作为复习。</p><a id="more"></a><hr><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>解决rare words的翻译问题。 <br></p><p>目前的word-level的方法效果并不算好。论文提到了back-off的方法，即对于rare words，首先翻译成 UNK，然后在look up dictionary去得到结果。但是翻译并不总是一对一的。 <br></p><p>还有直接把rare words复制到target sentence里，这样的方法或许对姓名之类的单词效果比较好。但存在的问题是翻译常常要求音译或者morphologic change(形态上的变化)，尤其是当单词表不同的时候。</p><h2 id="Method-s"><a href="#Method-s" class="headerlink" title="Method(s)"></a>Method(s)</h2><p><strong>Byte pair encoding(BPE</strong>)<img src="/images_2019.9.15/BPE.png" alt></p><p><em>vocab</em>是一个字典，键值表示每个单词出现的频率，这些单词已经被切割成一个个字符(也可以看成是subword unit)。<em>num_merges</em>即生成subword unit的数量，每次循环都生成一个subword unit。在每一个循环中，首先得到<em>pairs</em>，<em>get_stats</em>会得到所有相邻subword unit的，即任意(subword unit1, subword unit 2)的频率，然后存在<em>Pairs</em>里。在得到频率最高的pair即<em>best</em>后，用<em>merge_vocab</em>在<em>vocab</em>里把它们合并起来。</p><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>作者利用BPE和之前提到的word-level的方法，在数据集上测试效果，并且测量了unigram F1和BLEU（略）。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>BPE在训练数据更少的情况下取得了更好的效果。</p><h2 id="Future-Research"><a href="#Future-Research" class="headerlink" title="Future Research"></a>Future Research</h2><p>研究对于一个翻译任务的最优Vocabulary size。<br></p><p>研究针对双语来说，不仅利用一边的数据去得到Subword Unit，也利用另一边的数据去align。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Data Processing </tag>
            
            <tag> Machine Translation </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
