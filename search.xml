<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Neural Machine Translation of Rare Words with Subword Units]]></title>
    <url>%2F2019%2F09%2F15%2FNeural-Machine-Translation-of-Rare-Words-with-Subword-Units%2F</url>
    <content type="text"><![CDATA[Rico Sennrich and Barry Haddow and Alexandra BirchSchool of Informatics, University of Edinburghhttps://arxiv.org/pdf/1508.07909.pdfSummary文章主要是为了解决rare/out-of-vocabulary word的问题，在charator-based和word-based之间取了一个平衡。通过对训练数据进行分析，得出subword unit。因为在ESPNet看到了用subword unit去处理数据，BPE也已经应用在了语音领域，之前交流已经学习过了这个方法，因此再读一遍作为复习。 Problem Statement解决rare words的翻译问题。 目前的word-level的方法效果并不算好。论文提到了back-off的方法，即对于rare words，首先翻译成 UNK，然后在look up dictionary去得到结果。但是翻译并不总是一对一的。 还有直接把rare words复制到target sentence里，这样的方法或许对姓名之类的单词效果比较好。但存在的问题是翻译常常要求音译或者morphologic change(形态上的变化)，尤其是当单词表不同的时候。 Method(s)Byte pair encoding(BPE) vocab是一个字典，键值表示每个单词出现的频率，这些单词已经被切割成一个个字符(也可以看成是subword unit)。num_merges即生成subword unit的数量，每次循环都生成一个subword unit。在每一个循环中，首先得到pairs，get_stats会得到所有相邻subword unit的，即任意(subword unit1, subword unit 2)的频率，然后存在Pairs里。在得到频率最高的pair即best后，用merge_vocab在vocab里把它们合并起来。 Evaluation作者利用BPE和之前提到的word-level的方法，在数据集上测试效果，并且测量了unigram F1和BLEU（略）。 ConclusionBPE在训练数据更少的情况下取得了更好的效果。 Future Research研究对于一个翻译任务的最优Vocabulary size。 研究针对双语来说，不仅利用一边的数据去得到Subword Unit，也利用另一边的数据去align。]]></content>
      <tags>
        <tag>Data Processing</tag>
        <tag>Machine Translation</tag>
      </tags>
  </entry>
</search>
